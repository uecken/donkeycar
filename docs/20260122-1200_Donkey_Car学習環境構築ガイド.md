# Donkey Car 学習環境構築ガイド

**作成日**: 2026年1月22日
**最終更新**: 2026年1月22日
**対象**: Donkey Car >= 5.1 モデル学習環境
**情報源**: Donkey Car公式ドキュメント、TensorFlow公式ドキュメント、NVIDIA公式ドキュメント

---

## 目次

1. [概要](#1-概要)
2. [学習フロー](#2-学習フロー)
3. [OS・ソフトウェア要件](#3-osソフトウェア要件)
4. [ハードウェア要件](#4-ハードウェア要件)
5. [GPU対応状況とCUDA互換性](#5-gpu対応状況とcuda互換性)
6. [環境別セットアップ手順](#6-環境別セットアップ手順)
7. [Google Colabでの学習](#7-google-colabでの学習)
8. [学習コマンドとパラメータ](#8-学習コマンドとパラメータ)
9. [学習時間とデータ量の目安](#9-学習時間とデータ量の目安)
10. [環境比較と選択ガイド](#10-環境比較と選択ガイド)
11. [トラブルシューティング](#11-トラブルシューティング)
12. [参考資料](#12-参考資料)

---

## 1. 概要

### なぜPCで学習が必要か

Raspberry Piは処理能力が限られているため、Donkey Carのモデル学習はPCで行う必要があります。

| 環境 | 10,000枚の学習時間 | 実用性 |
|------|-------------------|--------|
| Raspberry Pi 4 (CPU) | 80時間以上 | 非現実的 |
| PC (CPU) | 約160分 | 可能だが遅い |
| PC (GPU) | **約1-5分** | **推奨** |
| Google Colab (GPU) | **約3-5分** | **推奨（無料）** |

### 対応環境一覧

| 環境 | GPU学習 | 推奨度 | 備考 |
|------|---------|--------|------|
| **Ubuntu 20.04/22.04** | 完全対応 | 最推奨 | 公式テスト済み |
| **WSL2 (Windows 10/11)** | 完全対応 | 推奨 | TensorFlow 2.11以降必須 |
| **Google Colab** | 完全対応 | 強く推奨 | 無料でGPU利用可 |
| macOS (Intel) | CPU のみ | 限定的 | GPU非対応 |
| macOS (Apple Silicon) | 限定対応 | 限定的 | tensorflow-metal使用 |
| Windows ネイティブ | 非対応 | 非推奨 | TensorFlow 2.10で終了 |

---

## 2. 学習フロー

### 全体ワークフロー

```
┌─────────────────────────────────────────────────────────────────┐
│                    Donkey Car 学習フロー                         │
└─────────────────────────────────────────────────────────────────┘

[1. データ収集 - Raspberry Pi]
    │  ・手動運転でトラックを走行
    │  ・毎秒20フレーム: 画像 + 操舵値 + スロットル値
    │  ・推奨: 10-20周回（5,000-20,000枚）
    ↓
[2. データ転送]
    │  rsync -rv pi@<IP>:~/mycar/data/ ~/mycar/data/
    ↓
[3. データクリーニング（オプション）]
    │  donkey tubclean
    │  ・不良データの削除
    │  ・クラッシュ時のデータ除去
    ↓
[4. モデル学習 - PC/Colab]
    │  donkey train --tub ./data/tub_* --model ./models/mypilot.h5
    │  ・自動的に .tflite も生成（v4.3.0以降）
    ↓
[5. モデル転送]
    │  scp models/mypilot.tflite pi@<IP>:~/mycar/models/
    ↓
[6. 自動運転テスト - Raspberry Pi]
       python manage.py drive --model models/mypilot.tflite
```

---

## 3. OS・ソフトウェア要件

### 公式サポートOS

| OS | バージョン | GPU対応 | 備考 |
|----|-----------|---------|------|
| **Ubuntu** | 20.04 LTS, 22.04 LTS | 完全対応 | 公式推奨・テスト済み |
| **Windows** | WSL2 (Win10 21H2+/Win11) | 完全対応 | ネイティブ対応は廃止 |
| **macOS** | 12.0 (Monterey) 以上 | 非対応 | CPU学習のみ |

### Python・パッケージ要件

| パッケージ | バージョン | 必須/任意 | 備考 |
|-----------|-----------|----------|------|
| **Python** | 3.11（64ビット） | 必須 | Donkey Car 5.1要件 |
| **pip** | 19.0以上（Linux/Win）、20.3以上（Mac） | 必須 | |
| **donkeycar** | >= 5.1 | 必須 | `pip install donkeycar[pc]` |
| **TensorFlow** | 2.15.x | 必須 | Keras学習用 |
| **PyTorch** | 2.1.x | 任意 | PyTorchモデル使用時 |
| **Miniconda** | 最新版 | 推奨 | 環境管理 |

### TensorFlow・CUDA互換性マトリックス

| TensorFlow | CUDA | cuDNN | Python | 備考 |
|------------|------|-------|--------|------|
| **2.15.x** | **12.2** | **8.9** | 3.9-3.11 | **推奨** |
| 2.14.x | 12.1 | 8.9 | 3.9-3.11 | |
| 2.13.x | 11.8 | 8.6 | 3.8-3.11 | |
| 2.10.x | 11.2 | 8.1 | 3.7-3.10 | Windows最終対応版 |

---

## 4. ハードウェア要件

### 最小構成（CPU学習）

| コンポーネント | 最小 | 推奨 |
|--------------|------|------|
| **CPU** | Intel Core i5 / AMD Ryzen 5 | Core i7 / Ryzen 7 |
| **RAM** | 8GB | 16GB |
| **ストレージ** | SSD 256GB | SSD 512GB |

### GPU学習構成

| 構成 | GPU | CPU | RAM | ストレージ | 価格帯 |
|------|-----|-----|-----|-----------|--------|
| **エントリー** | GTX 1660 (6GB) | Core i5/Ryzen 5 | 16GB | SSD 512GB | 約10-15万円 |
| **スタンダード** | RTX 3060 (12GB) | Core i5/Ryzen 5 | 16GB | SSD 512GB | 約15-20万円 |
| **ミドル** | RTX 4070 (12GB) | Core i7/Ryzen 7 | 32GB | NVMe 1TB | 約25-35万円 |
| **ハイエンド** | RTX 4090 (24GB) | Core i9/Ryzen 9 | 64GB | NVMe 2TB | 約50-70万円 |

### モデル別GPU VRAM要件

| モデルタイプ | 説明 | 最小VRAM | 推奨VRAM |
|------------|------|----------|----------|
| **linear** | 基本的なCNN、連続値出力 | 2GB | 4GB |
| **categorical** | 離散カテゴリ出力（15ビン） | 2GB | 4GB |
| **memory** | 過去の操作履歴を入力 | 2GB | 4GB |
| **imu** | IMUデータ統合 | 2GB | 4GB |
| **behavioral** | 行動条件付きモデル | 2GB | 4GB |
| **rnn/lstm** | LSTM時系列モデル | 4GB | 8GB |
| **3d_cnn** | 3D畳み込み（20フレーム） | 6GB | 8-12GB |

---

## 5. GPU対応状況とCUDA互換性

### TensorFlow GPU要件

| 要件 | 値 |
|------|-----|
| **最小Compute Capability** | 3.5 |
| **推奨Compute Capability** | 7.0以上 |
| **最適Compute Capability** | 8.0以上 |

### 主要GPU対応表

| GPU | VRAM | Compute Capability | TensorFlow対応 | Donkey Car対応 |
|-----|------|-------------------|---------------|---------------|
| **GTX 1050 Ti** | 4GB | 6.1 | 対応 | 対応（軽量モデル） |
| **GTX 1060** | 6GB | 6.1 | 対応 | 対応 |
| **GTX 1650** | 4GB | 7.5 | 対応 | 対応（軽量モデル） |
| **GTX 1660** | 6GB | **7.5** | **対応** | **対応** |
| **GTX 1660 Super** | 6GB | 7.5 | 対応 | 対応 |
| **GTX 1660 Ti** | 6GB | 7.5 | 対応 | 対応 |
| **RTX 2060** | 6GB | 7.5 | 対応 | 対応 |
| **RTX 2070** | 8GB | 7.5 | 対応 | 対応 |
| **RTX 2080** | 8GB | 7.5 | 対応 | 対応 |
| **RTX 3060** | 12GB | 8.6 | 対応 | 対応（推奨） |
| **RTX 3070** | 8GB | 8.6 | 対応 | 対応 |
| **RTX 3080** | 10GB | 8.6 | 対応 | 対応 |
| **RTX 4070** | 12GB | 8.9 | 対応 | 対応（推奨） |
| **RTX 4080** | 16GB | 8.9 | 対応 | 対応 |
| **RTX 4090** | 24GB | 8.9 | 対応 | 対応 |
| **Tesla T4** | 16GB | 7.5 | 対応 | 対応（Colab） |
| **Tesla V100** | 16/32GB | 7.0 | 対応 | 対応（Colab Pro） |
| **A100** | 40/80GB | 8.0 | 対応 | 対応（クラウド） |

### GTX 1660シリーズの詳細

GTX 1660シリーズはDonkey Carの学習に**完全対応**しています。

| 項目 | 値 |
|------|-----|
| CUDA Compute Capability | **7.5**（TensorFlow要件3.5を大幅に超過） |
| アーキテクチャ | Turing |
| Tensor Core | **非搭載**（RTX 20シリーズ以降から搭載） |
| 混合精度学習（FP16） | 恩恵は限定的 |
| Donkey Car学習 | **十分な性能** |

### 必要なソフトウェアスタック

| コンポーネント | Ubuntu | WSL2 | 備考 |
|--------------|--------|------|------|
| **NVIDIA Driver** | 525.60.13以上 | Windows側528.33以上 | WSL2はWindowsドライバを使用 |
| **CUDA Toolkit** | 12.2〜12.3 | 12.3（WSL-Ubuntu版） | |
| **cuDNN** | 8.9.7 | 8.9.x | |
| **TensorFlow** | 2.15.x | 2.15.x | `pip install tensorflow[and-cuda]` |

---

## 6. 環境別セットアップ手順

### 6.1 Ubuntu（推奨）

#### Step 1: システム更新と基本パッケージ

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y python3-pip python3-venv python3-dev \
    libatlas-base-dev libopenjp2-7 libtiff5 git
```

#### Step 2: NVIDIAドライバインストール

```bash
# 推奨ドライバを自動インストール
sudo apt install -y ubuntu-drivers-common
sudo ubuntu-drivers autoinstall
sudo reboot

# インストール確認
nvidia-smi
```

#### Step 3: CUDA Toolkit 12.2インストール

```bash
# CUDA リポジトリ追加
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt update

# CUDA Toolkit インストール
sudo apt install -y cuda-toolkit-12-2

# 環境変数設定
echo 'export PATH=/usr/local/cuda-12.2/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# 確認
nvcc --version
```

#### Step 4: cuDNNインストール

```bash
sudo apt install -y libcudnn8 libcudnn8-dev
```

#### Step 5: Minicondaインストール（推奨）

```bash
# ダウンロード・インストール
curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o Miniconda3.sh
bash Miniconda3.sh -b -p $HOME/miniconda3
source ~/.bashrc

# conda初期化
~/miniconda3/bin/conda init
source ~/.bashrc
```

#### Step 6: Donkey Car環境構築

```bash
# 仮想環境作成
conda create -n donkey python=3.11 -y
conda activate donkey

# Donkey Car インストール
pip install donkeycar[pc]

# TensorFlow GPU インストール
pip install 'tensorflow[and-cuda]==2.15.*'

# GPU認識確認
python -c "import tensorflow as tf; print('GPU:', tf.config.list_physical_devices('GPU'))"
```

#### Step 7: プロジェクト作成

```bash
donkey createcar --path ~/mycar
cd ~/mycar
```

---

### 6.2 WSL2（Windows 10/11）

#### 前提条件

| 項目 | 要件 |
|------|------|
| Windows | Windows 10 21H2以上 / Windows 11 |
| WSL | WSL2（WSL1は非対応） |
| NVIDIA Driver | **Windows側**に528.33以上をインストール |

> **重要**: WSL2内にNVIDIA Linuxドライバをインストール**しないでください**。Windows側のドライバがWSL2内で自動的に使用されます。

#### Step 1: WSL2インストール

```powershell
# PowerShell（管理者権限）で実行
wsl --install Ubuntu-22.04

# または既存のWSLをアップデート
wsl --update
```

#### Step 2: Ubuntu初期設定

```bash
# Ubuntu起動後
sudo apt-get update && sudo apt-get upgrade -y
sudo apt install -y python3-pip python3-venv python3-dev git
sudo apt-get install -y libmtdev1 libgl1 xclip
```

#### Step 3: 環境変数設定

```bash
# .bashrcに追加
echo 'export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6' >> ~/.bashrc
source ~/.bashrc
```

#### Step 4: CUDA Toolkit インストール（WSL2専用）

```bash
# WSL-Ubuntu用CUDAリポジトリ
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update

# CUDA Toolkit インストール
sudo apt-get install -y cuda-toolkit-12-3

# 環境変数
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

#### Step 5: cuDNNインストール

```bash
sudo apt-get install -y libcudnn8 libcudnn8-dev
```

#### Step 6: Minicondaインストール

```bash
curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o Miniconda3.sh
bash Miniconda3.sh -b -p $HOME/miniconda3
source ~/.bashrc
~/miniconda3/bin/conda init
source ~/.bashrc
```

#### Step 7: Donkey Car環境構築

```bash
conda create -n donkey python=3.11 -y
conda activate donkey
pip install donkeycar[pc]
pip install 'tensorflow[and-cuda]==2.15.*'

# GPU認識確認
python -c "import tensorflow as tf; print('GPU:', tf.config.list_physical_devices('GPU'))"
```

#### WSL2メモリ設定（推奨）

`C:\Users\<ユーザー名>\.wslconfig` を作成：

```ini
[wsl2]
memory=16GB
processors=8
swap=8GB
```

設定後、PowerShellで `wsl --shutdown` を実行して再起動。

#### WSL2でのファイル共有

```bash
# Windows側のファイルにアクセス
cd /mnt/c/Users/<ユーザー名>/Documents/

# Raspberry PiからWSL2へ直接転送
rsync -rv pi@raspberrypi:~/mycar/data/ ~/mycar/data/
```

---

### 6.3 macOS（CPU学習のみ）

#### Intel Mac

```bash
# Miniconda環境
conda create -n donkey python=3.11 -y
conda activate donkey
pip install donkeycar[pc]
```

#### Apple Silicon Mac

```bash
conda create -n donkey python=3.11 -y
conda activate donkey
pip install donkeycar[macos]

# tensorflow-metal（オプション・実験的）
pip install tensorflow-metal
```

> **注意**: macOSではNVIDIA GPUがサポートされないため、CPU学習のみとなります。学習時間は大幅に長くなります。

---

## 7. Google Colabでの学習

### 概要

Google Colabは**無料**でGPU学習が可能な最も手軽な選択肢です。

| 項目 | 無料版 | Pro（$10/月） | Pro+（$50/月） |
|------|-------|--------------|----------------|
| GPU | Tesla T4 | T4/V100 | V100/A100 |
| セッション時間 | 最大12時間 | 最大24時間 | 最大24時間 |
| GPU割り当て | 週30時間程度 | 優先割り当て | 最優先 |
| アイドルタイムアウト | 90分 | 延長 | さらに延長 |
| RAM | 12GB | 25GB | 52GB |

### 公式ノートブック

**Robocarstore提供のノートブック**が最も実績があります：

- **GitHub**: [robocarstore/donkey-car-training-on-google-colab](https://github.com/robocarstore/donkey-car-training-on-google-colab)
- **Colab直接リンク**: [Open in Colab](https://colab.research.google.com/github/robocarstore/donkey-car-training-on-google-colab/blob/master/Donkey_Car_Training_using_Google_Colab.ipynb)

### 手動セットアップ手順

#### Step 1: 新規ノートブック作成

1. [Google Colab](https://colab.research.google.com/) にアクセス
2. 「新しいノートブック」を作成
3. 「ランタイム」→「ランタイムのタイプを変更」→「GPU」を選択

#### Step 2: GPU確認

```python
# GPU利用可能性を確認
!nvidia-smi
```

#### Step 3: Donkey Carインストール

```python
# リポジトリクローン
!git clone https://github.com/autorope/donkeycar.git
%cd donkeycar
!git checkout main
!pip install -e .[pc]
```

#### Step 4: プロジェクト作成

```python
!donkey createcar --path /content/mycar
%cd /content/mycar
```

#### Step 5: データアップロード

**方法A: Google Drive経由（推奨）**

```python
from google.colab import drive
drive.mount('/content/drive')

# Driveからデータをコピー
!cp -r /content/drive/MyDrive/donkey_data/tub_* /content/mycar/data/
```

**方法B: 直接アップロード**

```python
from google.colab import files
uploaded = files.upload()  # tub.zipをアップロード
!unzip tub.zip -d data/
```

#### Step 6: 学習実行

```python
# 学習実行
!donkey train --tub ./data/tub_* --model ./models/mypilot.h5
```

#### Step 7: モデルダウンロード

```python
from google.colab import files

# Kerasモデル
files.download('./models/mypilot.h5')

# TFLiteモデル（Raspberry Pi用）
files.download('./models/mypilot.tflite')
```

### Colabワークフロー図

```
[Raspberry Pi]
    │ データ収集（tub形式）
    ↓
[ローカルPC]
    │ rsync/scpで転送
    │ zip圧縮
    ↓
[Google Drive]
    │ アップロード
    ↓
[Google Colab]
    │ Driveマウント
    │ 学習実行（GPU）
    │ モデルダウンロード
    ↓
[ローカルPC]
    │ scpで転送
    ↓
[Raspberry Pi]
    └ 自動運転実行
```

---

## 8. 学習コマンドとパラメータ

### 基本コマンド

```bash
# 基本学習
donkey train --tub ./data/tub_* --model ./models/mypilot.h5

# 複数tubを指定
donkey train --tub ./data/tub_1,./data/tub_2 --model ./models/mypilot.h5

# モデルタイプを指定
donkey train --tub ./data/tub_* --model ./models/mypilot.h5 --type categorical
```

### モデルタイプオプション

| オプション | モデル | 用途 |
|-----------|--------|------|
| `--type linear` | KerasLinear | 連続値出力（デフォルト） |
| `--type categorical` | KerasCategorical | 離散カテゴリ出力 |
| `--type rnn` | KerasRNN | LSTM時系列 |
| `--type 3d` | Keras3D | 3D畳み込み |
| `--type imu` | KerasIMU | IMUデータ統合 |
| `--type behavior` | KerasBehavioral | 行動条件付き |
| `--type latent` | KerasLatent | オートエンコーダベース |

### 主要設定パラメータ（myconfig.py）

```python
# 学習設定
BATCH_SIZE = 128              # バッチサイズ
TRAIN_TEST_SPLIT = 0.8        # 学習/検証分割
MAX_EPOCHS = 100              # 最大エポック数
USE_EARLY_STOP = True         # 早期終了
EARLY_STOP_PATIENCE = 5       # 改善なし許容エポック数

# 画像設定
IMAGE_W = 160                 # 画像幅
IMAGE_H = 120                 # 画像高さ
IMAGE_DEPTH = 3               # チャンネル数（RGB）

# 拡張設定（v4.3.0以降）
AUGMENTATIONS = ['BLUR', 'BRIGHTNESS']  # 画像拡張
```

### TFLite変換

```bash
# 学習時に自動生成（v4.3.0以降）
# または手動変換
donkey train --tub ./data/tub_* --model ./models/mypilot.tflite --type tflite
```

---

## 9. 学習時間とデータ量の目安

### データ量の目安

| 用途 | 画像数 | 走行時間（20Hz） | データサイズ |
|------|--------|-----------------|-------------|
| テスト・練習 | 1,000枚 | 約50秒 | 約3MB |
| 基本学習 | 5,000-10,000枚 | 約4-8分 | 約15-30MB |
| 実用レベル | 15,000-30,000枚 | 約12-25分 | 約50-100MB |
| 高精度 | 50,000枚以上 | 約40分以上 | 150MB以上 |

### ハードウェア別学習時間比較

| ハードウェア | 1,000枚 | 10,000枚 | 50,000枚 |
|-------------|---------|----------|----------|
| **Raspberry Pi 4 (CPU)** | 8-10時間 | 非推奨 | 非推奨 |
| **MacBook Air M1 (CPU)** | 約2分 | 約20分 | 約100分 |
| **Intel Core i7 (CPU)** | 約16分 | 約160分 | 約13時間 |
| **GTX 1660 (GPU)** | 約15秒 | 約2-3分 | 約10-15分 |
| **RTX 2080 (GPU)** | 約10秒 | 約1-2分 | 約8分 |
| **RTX 3060 (GPU)** | 約8秒 | 約1分 | 約6分 |
| **RTX 4070 (GPU)** | 約7秒 | 約50秒 | 約5分 |
| **RTX 4090 (GPU)** | 約5秒 | 約30秒 | 約3分 |
| **Tesla T4 (Colab)** | 約12秒 | 約2-3分 | 約10分 |
| **Tesla V100 (Colab Pro)** | 約8秒 | 約1分 | 約5分 |

---

## 10. 環境比較と選択ガイド

### 環境比較表

| 項目 | Ubuntu直接 | WSL2 | Google Colab | macOS |
|------|-----------|------|--------------|-------|
| **GPU学習** | 完全対応 | 完全対応 | 完全対応 | 非対応 |
| **セットアップ** | 中程度 | やや複雑 | 簡単 | 簡単 |
| **初期コスト** | PC+GPU代 | PC+GPU代 | 無料 | Mac代 |
| **月額コスト** | 電気代のみ | 電気代のみ | 無料〜$50 | 電気代のみ |
| **制限** | なし | Windows依存 | 時間制限 | CPU学習のみ |
| **データ転送** | 直接 | 直接 | アップロード必要 | 直接 |
| **学習速度** | 最速 | 高速 | 高速 | 遅い |

### 状況別推奨環境

| 状況 | 推奨環境 | 理由 |
|------|---------|------|
| **初めてDonkey Carを試す** | Google Colab（無料） | セットアップ不要、無料 |
| **Windowsユーザー** | WSL2 + 既存GPU | ネイティブ非対応のため |
| **GTX 1660所有** | Ubuntu直接 or WSL2 | 十分な性能、長期利用 |
| **頻繁に学習する** | ローカルGPU | 時間制限なし |
| **GPU購入を避けたい** | Colab Pro（$10/月） | 年間約15,000円 |
| **チーム開発** | Ubuntu + RTX 4070以上 | 安定性・共有性 |
| **研究・大規模** | クラウドA100/H100 | 高性能・スケーラブル |

### コスト比較

| 選択肢 | 初期コスト | 年間運用 | 1年間総コスト |
|--------|-----------|---------|--------------|
| **Google Colab（無料）** | 0円 | 0円 | 0円 |
| **Google Colab Pro** | 0円 | 約15,000円 | 約15,000円 |
| **GTX 1660（中古）** | 約20,000円 | 電気代約5,000円 | 約25,000円 |
| **RTX 3060（新品）** | 約40,000円 | 電気代約6,000円 | 約46,000円 |
| **RTX 4070（新品）** | 約90,000円 | 電気代約7,000円 | 約97,000円 |

### クラウドGPUサービス比較

| サービス | GPU | 無料枠 | 有料価格 |
|---------|-----|-------|---------|
| **Google Colab** | T4 | 週30時間程度 | Pro: $10/月 |
| **Kaggle Notebooks** | T4 | 週30時間 | なし |
| **AWS SageMaker Studio Lab** | T4 | 4時間/セッション | なし |
| **AWS g4dn.xlarge** | T4 | なし | $0.50-0.70/時間 |
| **GCP T4 Spot** | T4 | なし | $0.12-0.20/時間 |
| **Runpod** | RTX 4090 | なし | $0.44/時間 |
| **Vast.ai** | A100 | なし | ~$0.66/時間 |

---

## 11. トラブルシューティング

### 共通の問題

| 問題 | 原因 | 解決策 |
|------|------|--------|
| GPUが認識されない | ドライバ/CUDAバージョン不一致 | `nvidia-smi`で確認、ドライバ更新 |
| TensorFlowがGPUを使わない | tensorflow-cpuがインストール済み | `pip uninstall tensorflow` 後に `pip install tensorflow[and-cuda]` |
| メモリ不足（OOM） | バッチサイズが大きすぎる | `BATCH_SIZE`を減らす（64, 32など） |
| 学習が収束しない | データ品質の問題 | `donkey tubclean`で不良データ削除 |

### WSL2固有の問題

| 問題 | 解決策 |
|------|--------|
| GPUが認識されない | Windows側のNVIDIAドライバを最新版に更新 |
| NUMAサポート警告 | 無視して問題なし（WSL2の仕様） |
| Donkey UIがぼやける | NVIDIAコントロールパネルで3Dレンダリングモードを「品質」に変更 |
| メモリ不足 | `.wslconfig`でメモリ割り当てを増やす |
| WSL内でGPUドライバエラー | WSL内にNVIDIAドライバをインストールしていないか確認 |

### Google Colab固有の問題

| 問題 | 解決策 |
|------|--------|
| GPUが割り当てられない | 時間をおいて再試行、または Colab Pro にアップグレード |
| セッションが切断される | ブラウザのタブをアクティブに保つ、Colab Pro を検討 |
| ファイルが消える | Google Driveにデータを保存 |
| パッケージインストールエラー | セルを再実行、またはランタイムを再起動 |

### GPU認識確認コマンド

```bash
# NVIDIAドライバ確認
nvidia-smi

# CUDA確認
nvcc --version

# TensorFlow GPU確認
python -c "import tensorflow as tf; print('GPU:', tf.config.list_physical_devices('GPU'))"

# PyTorch GPU確認（PyTorch使用時）
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('Device:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')"
```

---

## 12. 参考資料

### Donkey Car公式

- [Donkey Car公式ドキュメント](https://docs.donkeycar.com/)
- [Install on Linux](https://docs.donkeycar.com/guide/host_pc/setup_ubuntu/)
- [Install on Windows (WSL2)](https://docs.donkeycar.com/guide/host_pc/setup_windows/)
- [Install on Mac](https://docs.donkeycar.com/guide/host_pc/setup_mac/)
- [Train Autopilot](https://docs.donkeycar.com/guide/deep_learning/train_autopilot/)
- [Keras Parts](https://docs.donkeycar.com/parts/keras/)

### TensorFlow・CUDA

- [TensorFlow公式 - pip install](https://www.tensorflow.org/install/pip)
- [TensorFlow GPU Support](https://www.tensorflow.org/install/gpu)
- [NVIDIA CUDA対応GPUリスト](https://developer.nvidia.com/cuda-gpus)
- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)
- [NVIDIA cuDNN](https://developer.nvidia.com/cudnn)

### WSL2・Windows

- [NVIDIA CUDA on WSL User Guide](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)
- [Microsoft Learn - Enable NVIDIA CUDA on WSL 2](https://learn.microsoft.com/en-us/windows/ai/directml/gpu-cuda-in-wsl)
- [FreeCodeCamp - CUDA and WSL2 Setup Guide](https://www.freecodecamp.org/news/how-to-set-up-cuda-and-wsl2-for-windows-11-including-pytorch-and-tensorflow-gpu/)

### Google Colab

- [Google Colab](https://colab.research.google.com/)
- [Robocarstore Colab Notebook](https://github.com/robocarstore/donkey-car-training-on-google-colab)
- [sachindroid8 Self-Driving Car Colab](https://github.com/sachindroid8/self-driving-car-using-google-colab)

### その他クラウドGPU

- [Kaggle Notebooks](https://www.kaggle.com/code)
- [AWS SageMaker Studio Lab](https://studiolab.sagemaker.aws/)
- [Runpod](https://www.runpod.io/)
- [Vast.ai](https://vast.ai/)

---

## 更新履歴

| 日付 | 内容 |
|------|------|
| 2026年1月22日 | 初版作成 - 2つの資料を統合、内容を詳細化 |
