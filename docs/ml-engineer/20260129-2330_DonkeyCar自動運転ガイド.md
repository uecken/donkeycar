# Donkey Car 自動運転ガイド

**作成日**: 2026年1月29日
**担当**: ml-engineer
**対象**: Donkey Car の自動運転（Autopilot）機能

---

## 概要

このドキュメントでは、Donkey Carの自動運転機能について、データ収集から学習、推論までの全プロセスを説明します。

---

## 目次

1. [データ収集（Tubデータ）](#1-データ収集tubデータ)
2. [モデル学習の手順](#2-モデル学習の手順)
3. [自動運転モードの起動](#3-自動運転モードの起動)
4. [利用可能なモデルタイプ](#4-利用可能なモデルタイプ)
5. [TensorFlow vs PyTorch](#5-tensorflow-vs-pytorch)
6. [モデル転送と推論最適化](#6-モデル転送と推論最適化)
7. [実践フロー](#7-実践フロー)

---

## 1. データ収集（Tubデータ）

### Tubの概要

TubはDonkey Carのデータ保存フォーマットです。

**主な特徴**:
- 画像、センサーデータ、制御命令をまとめて保存
- JSON形式のメタデータ + バイナリ画像データ
- 複数のドライブセッションを1つのTubに保存可能

### データ構造

```
~/mycar/data/
├── tub_1_20260129-120000/
│   ├── manifest.json       # Tubメタデータ
│   ├── record_1.json       # レコード1メタデータ
│   ├── record_1_cam.jpg    # 画像1
│   ├── record_2.json
│   ├── record_2_cam.jpg
│   └── ...
```

### 記録されるデータ

| データ | キー | 型 |
|--------|------|-----|
| カメラ画像 | `cam/image_array` | image_array (120x160x3) |
| 操舵角 | `user/angle` | float (-1.0 〜 1.0) |
| スロットル | `user/throttle` | float (-1.0 〜 1.0) |
| モード | `user/mode` | str |

### データ収集コマンド

```bash
cd ~/mycar
python manage.py drive

# WebUI (http://localhost:8887) で:
# 1. "User" モードを選択
# 2. "Start Recording" を押す
# 3. 手動で走行
# 4. "Stop Recording" で終了
```

### データ収集のコツ

1. **多様なデータを収集**: 直進、左折、右折を均等に
2. **一定速度で走行**: 急加減速は避ける
3. **コースを複数周回**: 5〜10周以上推奨
4. **失敗データは削除**: コースアウトや衝突時のデータは除去

---

## 2. モデル学習の手順

### 学習フロー

```
1. Tubデータ読み込み
   ↓
2. 訓練/検証データ分割 (80/20)
   ↓
3. データ前処理・拡張
   ↓
4. モデル作成・コンパイル
   ↓
5. 訓練（EarlyStopping付き）
   ↓
6. TFLite変換（オプション）
```

### 学習コマンド

```bash
# 基本学習
python train.py --tubs=data/ --model=models/pilot.h5 --type=linear

# 特定のTubを指定
python train.py --tubs=data/tub_1,data/tub_2 --model=models/pilot.h5

# モデルタイプを指定
python train.py --tubs=data/ --model=models/pilot.h5 --type=categorical
```

### 学習設定（myconfig.py）

```python
# 基本学習設定
MAX_EPOCHS = 100
BATCH_SIZE = 128
TRAIN_TEST_SPLIT = 0.8
EARLY_STOP_PATIENCE = 5

# モデル設定
DEFAULT_MODEL_TYPE = 'linear'

# 画像設定
IMAGE_W = 160
IMAGE_H = 120
IMAGE_DEPTH = 3

# TFLite変換
CREATE_TF_LITE = True
```

### 学習結果の確認

```bash
# 学習履歴の確認
ls -la models/

# 出力ファイル
# models/pilot.h5      - Kerasモデル
# models/pilot.tflite  - TFLiteモデル（Pi推論用）
# models/pilot.json    - モデルメタデータ
```

---

## 3. 自動運転モードの起動

### ドライブシステムフロー（20Hz）

```
1. カメラ入力 → cam/image_array
   ↓
2. コントローラ読み取り → user/mode, user/angle, user/throttle
   ↓
3. モード判定
   - "user" → マニュアル運転
   - "local_angle" → 操舵のみ自動
   - "local" → 完全自動
   ↓
4. 自動操縦実行（local時）
   - モデル推論 → pilot/angle, pilot/throttle
   ↓
5. アクチュエータ制御 → PWM出力
```

### 自動運転コマンド

```bash
# モデル指定でドライブ開始
python manage.py drive --model=models/pilot.h5 --type=linear

# TFLiteモデル使用（推奨）
python manage.py drive --model=models/pilot.tflite --type=linear

# ジョイスティック併用
python manage.py drive --model=models/pilot.h5 --js
```

### モード切替

| モード | 説明 | 操舵 | スロットル |
|--------|------|------|-----------|
| **User** | マニュアル | 手動 | 手動 |
| **Local Angle** | 半自動 | 自動 | 手動 |
| **Local Pilot** | 完全自動 | 自動 | 自動 |

**切替方法**:
- WebUI (http://localhost:8887) のドロップダウン
- ジョイスティックのボタン（設定による）

---

## 4. 利用可能なモデルタイプ

### Kerasモデル一覧

| モデル | コマンド | 説明 | 用途 |
|--------|---------|------|------|
| **Linear** | `linear` | シンプルCNN+Dense | 基本（推奨） |
| **Categorical** | `categorical` | カテゴリカル出力 | 安定した操舵 |
| **Memory** | `memory` | 過去命令を統合 | スムーズな操舵 |
| **IMU** | `imu` | 画像+IMU入力 | IMU装着車両 |
| **Behavioral** | `behavioral` | 行動条件付き | 複数走行スタイル |
| **LSTM** | `lstm_seq` | RNN時系列 | 長期依存性 |
| **3D CNN** | `3d` | 3D畳み込み | 動的環境 |

### モデル選択の指針

| 状況 | 推奨モデル |
|------|-----------|
| 初めての学習 | `linear` |
| 安定性重視 | `categorical` |
| 滑らかな操舵 | `memory` |
| IMU搭載車 | `imu` |

### Linear vs Categorical

**Linear**:
```python
# 出力: 連続値
angle: float (-1.0 〜 1.0)
throttle: float (-1.0 〜 1.0)
```

**Categorical**:
```python
# 出力: 確率分布
angle_bins: [0.1, 0.2, 0.5, 0.15, 0.05, ...]  # 15ビン
throttle_bins: [0.1, 0.3, 0.4, 0.2, ...]       # 20ビン
```

Categoricalは離散化により安定するが、精度は若干低下。

---

## 5. TensorFlow vs PyTorch

### フレームワーク比較

| 項目 | TensorFlow/Keras | PyTorch |
|------|------------------|---------|
| デフォルト | ✓ | - |
| TFLite変換 | ✓ | ✗ |
| Raspberry Pi推論 | ✓（推奨） | △ |
| GPU学習 | ✓ | ✓ |
| モデル種類 | 9種類 | 3種類 |

### 推奨

**学習環境**: TensorFlow/Keras（GPUサーバー）
**推論環境**: TFLite（Raspberry Pi）

```bash
# 学習（WSL2/GPUサーバー）
python train.py --tubs=data/ --model=models/pilot.h5 --type=linear

# 推論（Raspberry Pi）
python manage.py drive --model=models/pilot.tflite
```

---

## 6. モデル転送と推論最適化

### モデル転送

```bash
# SCPでRaspberry Piへ転送
scp models/pilot.tflite koito@192.168.50.3:~/mycar/models/
```

### ファイルサイズ比較

| 形式 | サイズ | 推論速度（Pi4） | 用途 |
|------|--------|-----------------|------|
| .h5 | 10-50MB | 100-200ms | 学習・検証 |
| .tflite | 3-10MB | 30-50ms | **★Pi推論（推奨）** |
| .tflite (int8) | 1-3MB | 20-30ms | リアルタイム重視 |

### TFLite変換

```python
# 学習時に自動生成（CREATE_TF_LITE = True）

# 手動変換
from donkeycar.parts.interpreter import keras_model_to_tflite
keras_model_to_tflite('models/pilot.h5', 'models/pilot.tflite')
```

### INT8量子化（オプション）

```python
# より高速だが精度が若干低下
# Coral TPU使用時に有効
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = calibration_data
```

---

## 7. 実践フロー

### 最小限の自動運転フロー

```bash
# === Step 1: データ収集（Raspberry Pi）===
cd ~/mycar
python manage.py drive
# WebUIで "User" モード、記録ON、手動で5-10周走行

# === Step 2: データ転送（Pi → PC）===
scp -r koito@192.168.50.3:~/mycar/data/ ./data/

# === Step 3: 学習（GPU搭載PC/WSL2）===
cd ~/donkeycar
python train.py --tubs=data/ --model=models/pilot.h5 --type=linear

# === Step 4: モデル転送（PC → Pi）===
scp models/pilot.tflite koito@192.168.50.3:~/mycar/models/

# === Step 5: 自動運転テスト（Raspberry Pi）===
ssh koito@192.168.50.3
cd ~/mycar
python manage.py drive --model=models/pilot.tflite --type=linear
# WebUIで "Local Pilot" に切り替え
```

### トラブルシューティング

| 問題 | 原因 | 解決策 |
|------|------|--------|
| 過学習 | データ不足 | Tubデータ追加、拡張設定 |
| 収束しない | 学習率が高い | BATCH_SIZE調整 |
| 推論が遅い | H5モデル使用 | TFLite変換 |
| コースアウト | データ偏り | 左右均等に収集 |
| 不安定な操舵 | Linear使用 | Categorical/Memoryに変更 |

### 推奨設定（myconfig.py）

```python
# 学習設定
MAX_EPOCHS = 100
BATCH_SIZE = 128
EARLY_STOP_PATIENCE = 5
CREATE_TF_LITE = True

# モデル設定
DEFAULT_MODEL_TYPE = 'linear'  # 初心者向け
# DEFAULT_MODEL_TYPE = 'categorical'  # 安定性重視

# 推論設定（Pi）
DRIVE_LOOP_HZ = 20  # 50msサイクル
```

---

## 関連資料

| 資料 | パス |
|------|------|
| 学習環境構築ガイド | [../devops-engineer/20260122-1200_Donkey_Car学習環境構築ガイド.md](../devops-engineer/20260122-1200_Donkey_Car学習環境構築ガイド.md) |
| WSL2環境セットアップ | [../devops-engineer/20260122-1510_WSL2学習環境セットアップ記録.md](../devops-engineer/20260122-1510_WSL2学習環境セットアップ記録.md) |
| DonkeyCar起動ガイド | [../robotcar-engineer/20260129-1830_DonkeyCar起動ガイド.md](../robotcar-engineer/20260129-1830_DonkeyCar起動ガイド.md) |

---

## 参考コード

### モデル定義（keras.py）

```python
# donkeycar/parts/keras.py - KerasLinear
def default_linear(input_shape=(120, 160, 3)):
    img_in = Input(shape=input_shape, name='img_in')

    # CNN特徴抽出
    x = Convolution2D(24, 5, strides=2, activation='relu')(img_in)
    x = Convolution2D(32, 5, strides=2, activation='relu')(x)
    x = Convolution2D(64, 5, strides=2, activation='relu')(x)
    x = Convolution2D(64, 3, strides=2, activation='relu')(x)
    x = Convolution2D(64, 3, strides=1, activation='relu')(x)
    x = Flatten()(x)

    # Dense層
    x = Dense(100, activation='relu')(x)
    x = Dense(50, activation='relu')(x)

    # 出力層
    angle_out = Dense(1, activation='linear', name='angle_out')(x)
    throttle_out = Dense(1, activation='linear', name='throttle_out')(x)

    return Model(inputs=[img_in], outputs=[angle_out, throttle_out])
```

---

## 更新履歴

| 日付 | 内容 |
|------|------|
| 2026年1月29日 | 初版作成 |
