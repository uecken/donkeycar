# Donkeycar 運転方式比較

**作成日**: 2026年2月11日 18:30
**担当**: ml-engineer
**目的**: Donkeycarの3つの運転方式（Deep Learning, Computer Vision, Path Follow）を比較整理

---

## 1. 概要

Donkeycarには3つの自動運転方式がある:

| 方式 | 手法 | データ収集 | 制御方式 |
|------|------|-----------|---------|
| **Deep Learning Autopilot** | 模倣学習（End-to-End） | 必要（人間運転） | ニューラルネットワーク |
| **Computer Vision Autopilot** | 画像処理 + PID制御 | 不要 | **制御工学（PID）** |
| **Path Follow** | 経路追従 | 不要（経路定義） | 幾何学的制御 |

---

## 2. Computer Vision Autopilot（制御工学方式）

### 2.1 概要

**制御工学に基づく方式**。ディープラーニングを使わず、伝統的な画像処理とPID制御で自動運転を実現。

```
【処理フロー】
カメラ画像
    ↓
色閾値処理（HSV）→ ラインを検出
    ↓
ヒストグラム → ラインの水平位置を特定
    ↓
PID制御器 → ステアリング値を計算
    ↓
ステップ制御 → スロットル値を計算
    ↓
出力: steering, throttle
```

### 2.2 LineFollower（標準実装）

**ファイル**: `donkeycar/parts/line_follower.py`

```python
class LineFollower:
    '''
    OpenCV based controller
    This controller takes a horizontal slice of the image at a set Y coordinate.
    Then it converts to HSV and does a color thresh hold to find the yellow pixels.
    It does a histogram to find the pixel of maximum yellow. Then is uses that pixel
    to guide a PID controller which seeks to maintain the max yellow at the same point
    in the image.
    '''
```

### 2.3 処理ステップ

#### Step 1: 水平スライス取得
```python
# 画像の特定の高さから水平スライスを取得
iSlice = self.scan_y  # 上から何ピクセルの位置
scan_line = cam_img[iSlice : iSlice + self.scan_height, :, :]
```

#### Step 2: HSV変換と色閾値処理
```python
# RGB → HSV変換
img_hsv = cv2.cvtColor(scan_line, cv2.COLOR_RGB2HSV)

# 黄色の範囲でマスク作成
mask = cv2.inRange(img_hsv, self.color_thr_low, self.color_thr_hi)
```

#### Step 3: ライン位置の検出
```python
# 水平方向のヒストグラムで最大値のピクセル位置を取得
hist = np.sum(mask, axis=0)
max_yellow = np.argmax(hist)  # ← ラインの水平位置
```

#### Step 4: PID制御でステアリング計算
```python
# PID制御器で目標位置との差からステアリング値を計算
self.steering = self.pid_st(max_yellow)
```

#### Step 5: スロットル制御
```python
# ラインからのずれに応じてスロットルを調整
if abs(max_yellow - self.target_pixel) > self.target_threshold:
    # ずれている → 減速
    self.throttle -= self.delta_th
else:
    # 正確 → 加速
    self.throttle += self.delta_th
```

### 2.4 設定パラメータ

**設定ファイル**: `donkeycar/templates/cfg_cv_control.py`

#### スキャン設定
```python
SCAN_Y = 100          # 上から何ピクセルでスキャン開始
SCAN_HEIGHT = 20      # スキャン範囲の高さ
```

#### 色閾値（HSV）
```python
COLOR_THRESHOLD_LOW  = (0, 50, 50)    # 暗い黄色（HSV）
COLOR_THRESHOLD_HIGH = (50, 255, 255) # 明るい黄色（HSV）
```

#### PID制御パラメータ
```python
PID_P = -0.01         # 比例ゲイン
PID_I = 0.000         # 積分ゲイン
PID_D = -0.0001       # 微分ゲイン
```

#### スロットル設定
```python
THROTTLE_MAX = 0.3    # 最大スロットル
THROTTLE_MIN = 0.15   # 最小スロットル
THROTTLE_STEP = 0.05  # スロットル変化量
```

---

## 3. 方式比較

### 3.1 技術的比較

| 項目 | Deep Learning | Computer Vision | Path Follow |
|------|--------------|-----------------|-------------|
| **基盤技術** | CNN（畳み込みNN） | OpenCV + PID | GPS/オドメトリ |
| **学習** | 必要（データ収集→学習） | 不要（パラメータ調整のみ） | 不要 |
| **制御方式** | End-to-End NN | **PID制御（制御工学）** | Pure Pursuit等 |
| **解釈可能性** | 低い（ブラックボックス） | **高い（アルゴリズム明確）** | 高い |
| **環境適応** | 学習データに依存 | パラメータ調整で対応 | 経路定義で対応 |

### 3.2 PID制御の詳細（制御工学）

**PID制御式**:
```
u(t) = Kp * e(t) + Ki * ∫e(t)dt + Kd * de(t)/dt

u(t)  : 制御出力（ステアリング）
e(t)  : 偏差（目標位置 - 現在位置）
Kp    : 比例ゲイン
Ki    : 積分ゲイン
Kd    : 微分ゲイン
```

**Donkeycarでの実装**:
```python
from simple_pid import PID

self.pid_st = PID(Kp=cfg.PID_P, Ki=cfg.PID_I, Kd=cfg.PID_D)
self.pid_st.setpoint = self.target_pixel  # 目標位置

# 制御出力の計算
self.steering = self.pid_st(max_yellow)
```

### 3.3 メリット・デメリット

#### Deep Learning Autopilot
| メリット | デメリット |
|---------|-----------|
| 複雑なシーンに対応可能 | データ収集が必要 |
| End-to-End学習 | 学習時間がかかる |
| 汎化性能が高い | ブラックボックス |

#### Computer Vision Autopilot（制御工学）
| メリット | デメリット |
|---------|-----------|
| **データ収集不要** | 対象色（黄色ライン）が必要 |
| **リアルタイム調整可能** | 照明変化に弱い |
| **アルゴリズムが明確** | 複雑なシーンに対応困難 |
| **計算負荷が低い** | ライン検出に特化 |

---

## 4. 使用方法

### 4.1 Computer Vision Autopilot の起動

```bash
# cv_control テンプレートで車両を作成
donkey createcar --path ~/mycar --template cv_control

# 設定ファイルを編集
cd ~/mycar
nano myconfig.py

# 走行
python manage.py drive
```

### 4.2 PIDパラメータのチューニング

```python
# myconfig.py

# Step 1: まずKpのみで調整（Ki, Kd = 0）
PID_P = -0.01
PID_I = 0.0
PID_D = 0.0

# Step 2: 振動を抑えるためKdを追加
PID_D = -0.0001

# Step 3: 定常偏差があればKiを追加
PID_I = 0.001
```

### 4.3 ジョイスティックでリアルタイム調整

```python
# ボタン設定
INC_PID_P_BTN = "R2"  # Pゲインを増加
DEC_PID_P_BTN = "L2"  # Pゲインを減少
```

---

## 5. 現プロジェクトへの適用

### 5.1 方式選択の判断

| 条件 | 推奨方式 |
|------|---------|
| 黄色ラインがあるコース | **Computer Vision** |
| 複雑なコース/ラインなし | Deep Learning |
| GPS/マーカーが使える | Path Follow |

### 5.2 現状

```
【現状】
コース: ラインあり/なし 要確認
採用: Deep Learning（模倣学習 linear）

【CV方式の検討】
- ラインがあればCV方式も有効
- PID制御でリアルタイム調整可能
- データ収集不要で即座にテスト可能
```

---

## 6. 技術的詳細

### 6.1 ファイル構成

| ファイル | 説明 |
|---------|------|
| `donkeycar/parts/line_follower.py` | LineFollower実装 |
| `donkeycar/templates/cv_control.py` | CV制御テンプレート |
| `donkeycar/templates/cfg_cv_control.py` | CV制御設定 |

### 6.2 カスタムCV制御の作成

```python
# myconfig.py でカスタムコントローラを指定
CV_CONTROLLER_MODULE = "my_cv_controller"
CV_CONTROLLER_CLASS = "MyLineFollower"
```

### 6.3 オーバーレイ表示

```python
OVERLAY_IMAGE = True  # Web UIでCV処理結果を表示
```

---

## 7. まとめ

| 項目 | Deep Learning | Computer Vision |
|------|--------------|-----------------|
| **手法** | ニューラルネットワーク | **画像処理 + PID制御** |
| **分類** | 機械学習 | **制御工学** |
| **データ収集** | 必要 | 不要 |
| **調整方法** | 再学習 | パラメータ変更 |
| **解釈可能性** | 低 | **高** |

### Computer Vision Autopilot の本質

```
【核心】
Computer Vision Autopilot = 画像処理（OpenCV） + 制御工学（PID制御）

- 機械学習は使わない
- 伝統的な制御工学アプローチ
- リアルタイムでパラメータ調整可能
- アルゴリズムが完全に解釈可能
```

---

## 8. 関連資料

- [Donkeycar公式ドキュメント - Computer Vision Autopilot](https://docs.donkeycar.com/guide/train_autopilot/#computer-vision-autopilot)
- [donkeycar/parts/line_follower.py](../../donkeycar/parts/line_follower.py) - LineFollower実装
- [donkeycar/templates/cfg_cv_control.py](../../donkeycar/templates/cfg_cv_control.py) - CV制御設定
- [20260208-1745_JetRacer_vs_Donkeycar比較.md](20260208-1745_JetRacer_vs_Donkeycar比較.md) - 学習方式比較

---

## 更新履歴

| 日付 | 内容 |
|------|------|
| 2026-02-11 18:30 | 初版作成 |
